---
title: "Working With Data Hosted on Hugging Face"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Working With Data Hosted on Hugging Face}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

---

```{r knitr_setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r general_setup, include=FALSE}
library(parkinsonsMetagenomicData)
library(dplyr)
library(DT)
```

# Hugging Face Overview and Setup

## Hugging Face

Individual pipeline output files have been combined into parquet files
and hosted in the
[metagenomics_mac](https://huggingface.co/datasets/waldronlab/metagenomics_mac)
repo on Hugging Face. Smaller versions of those same files, comprising only 10
samples per file, are available in the Hugging Face repo
[metagenomics_mac_examples](https://huggingface.co/datasets/waldronlab/metagenomics_mac_examples).
These are publicly accessible, and are able to be easily read using DuckDB.

## Parquet Creation

To create the individual parquet files, one needs credentials to access the
`gs://metagenomics-mac` Google Bucket. Instructions on obtaining these can be
found in the
[Google Cloud Storage vignette](vignettes/google_cloud_storage.Rmd). These
credentials are then substituted into the scripts found in the repo
[parquet_generation](https://github.com/ASAP-MAC/parquet_generation). These
scripts perform a number of transformations that increase searchability before
storing the combined data for each data type in parquet files.

## DuckDB in R

DuckDB is very easy to use in R through the `duckdb` R package. The `DBI` and
`dplyr`/`dbplyr` packages combine with it to provide a streamlined way to work
with remote data by selectively querying it before bringing it into your R
session.

Relevant tools:

 - [DuckDB R Client](https://duckdb.org/docs/stable/clients/r.html)
 - [DBI](https://dbi.r-dbi.org/)
 - [dplyr](https://dplyr.tidyverse.org/)/[dbplyr](https://dbplyr.tidyverse.org/)

# Standard Workflow

In the standard workflow, we have two main wrapper functions `accessParquetData`
and `loadParquetData`. `accessParquetData` sets up a DuckDB connection to the
parquet files hosted in Hugging Face. `loadParquetData` then takes an argument
for data type, and optionally arguments for specific sample UUIDs or a custom
filtering function and loads the requested data into R as a Tree Summarized
Experiment.

## Selecting Samples

First we select samples by browsing the `sampleMetadata` object. This is an
optional step, as those wishing to perform meta-analyses may wish to select
results across all samples.

```{r}
table(sampleMetadata$control, useNA = "ifany")
sample_data <- sampleMetadata %>%
    filter(control %in% c("Case", "Study Control") &
           age >= 16 &
           is.na(sex) != TRUE)

clade_name_ref <- load_ref("clade_name_ref")
feature_data_genus <- clade_name_ref %>%
    filter(grepl("Faecalibacterium", clade_name_genus)) %>%
    select(clade_name_genus, clade_name_species)
feature_data_species <- clade_name_ref %>%
    filter(grepl("prausnitzii", clade_name_species)) %>%
    select(clade_name_species)

local_files <- c("/home/kaelyn/Desktop/Work/r_packages/relative_abundance_clade_name_species.parquet",
                 "/home/kaelyn/Desktop/Work/r_packages/relative_abundance_uuid.parquet")

con <- accessParquetData(local_files = local_files)
DBI::dbListTables(con)

genus_ex <- loadParquetData(con, "relative_abundance",
                            filter_values = list(clade_name_genus = unique(feature_data_genus$clade_name_genus),
                                                 clade_name_species = unique(feature_data_genus$clade_name_species)))
genus_ex

species_ex <- loadParquetData(con, "relative_abundance",
                              filter_values = list(clade_name_species = unique(feature_data_species$clade_name_species)))
species_ex

# Show query
q_only <- loadParquetData(con, "relative_abundance",
                          filter_values = list(clade_name_genus = unique(feature_data_genus$clade_name_genus),
                                               clade_name_species = unique(feature_data_genus$clade_name_species)),
                          dry_run = TRUE)
show_query(q_only)
```

```{r}
table(sampleMetadata$control, useNA = "ifany")
sample_data <- sampleMetadata %>%
    filter(control %in% c("Case", "Study Control") &
           age >= 16 &
           is.na(sex) != TRUE)
sample_data_small <- sample_data[1:10,]
sample_data_one <- sample_data[1,]

clade_name_ref <- load_ref("clade_name_ref")
feature_data_genus <- clade_name_ref %>%
    filter(grepl("Faecalibacterium", clade_name_genus)) %>%
    select(clade_name_genus)

prof_genus <- profvis(returnSamples("relative_abundance", sample_data, feature_data_genus))
prof_genus_small <- profvis(returnSamples("relative_abundance", sample_data_small, feature_data_genus))
prof_genus_one <- profvis(returnSamples("relative_abundance", sample_data_one, feature_data_genus))

time_genus <- system.time(returnSamples("relative_abundance", sample_data, feature_data_genus))
time_genus_small <- system.time(returnSamples("relative_abundance", sample_data_small, feature_data_genus))
time_genus_one <- system.time(returnSamples("relative_abundance", sample_data_one, feature_data_genus))

prof_genus2 <- profvis(returnSamples("relative_abundance", sample_data, feature_data_genus, include_empty_samples = FALSE))
genus_ex <- returnSamples("relative_abundance", sample_data, feature_data_genus)
genus_ex

feature_data_species <- clade_name_ref %>%
    filter(grepl("prausnitzii", clade_name_species))
feature_data <- feature_data_species[1,]

species_ex <- returnSamples("relative_abundance", sample_data, feature_data_species)
species_ex

tex <- returnSamples("relative_abundance", sample_data, feature_data)

gene_family_ref <- load_ref("gene_family_ref")
feature_data_gf <- gene_family_ref %>%
    filter(grepl("UniRef90_A0A060BPF3", gene_family_uniref))

gf_ex <- returnSamples("genefamilies", sample_data, feature_data_gf, include_empty_samples = FALSE)
gf_ex
```

```{r pick_metadata}
selected_samples <- sampleMetadata |>
    filter(study_name == "ZhangM_2023") |>
    select(where(~ !any(is.na(.x))))
```

```{r show_metadata, echo=FALSE}
datatable(selected_samples, extensions = "Responsive")
```

The `uuid` column contains the UUIDs we will provide for `loadParquetData`.

```{r pull_uuids}
selected_uuids <- selected_samples$uuid
selected_uuids
```

## Hugging Face and DuckDB Connection

Then we can call `get_hf_parquet_urls` to examine the files available in the
repo. From the result, we can select values of data_type that we are interested
in querying.

```{r view_files_in_repo}
avail_files <- get_hf_parquet_urls(repo_name = "waldronlab/metagenomics_mac")
```
```{r display_files_in_repo, echo=FALSE}
datatable(avail_files, extensions = "Responsive")
```

We then run `accessParquetData`, which creates the DuckDB connection and sets
up DuckDB "VIEW" objects for each available file type. It returns a DuckDB
connection object. The `data_types` argument can be left blank to do this for
all available file types, or a smaller number can be provided. Here we will
select the MetaPhlAn relative_abundance data type. DBI functions can be used to
see which views are now available.

```{r access_wrapper}
con <- accessParquetData(data_types = "relative_abundance")

# Show tables
DBI::dbListTables(con)
```

## Loading into R

We can then take a look at the columns available for our chosen data type with
`parquet_colinfo` and decide how we want to filter the full parquet file. A
good starting place is to filter by the uuid column to select only rows
pertaining to our selected samples. Additional filters can be provided, but
certain considerations may need to be made when dealing with large file types
(see [Large File Considerations](## Large File Considerations)).

```{r colinfo}
# Show colinfo
colinfo <- parquet_colinfo("relative_abundance")
```
```{r display_colinfo}
datatable(colinfo, extensions = "Responsive")
```

To set up filtering arguments, format them as a named list. The element name is
the column to filter by, and the element values will be exact matches.

```{r filter_vals}
filter_values <- list(uuid = selected_samples$uuid,
                      clade_name_species = "s__Faecalibacterium_prausnitzii")
```

We then provide that set of filtering arguments to `loadParquetData` along with
the database connection object and the data type we are accessing and receive a
Tree Summarized Experiment object. Loading the data may take a few seconds
depending on the file type and queries.

```{r load_wrapper}
basic_se <- loadParquetData(con,
                            data_type = "relative_abundance",
                            filter_values = filter_values)
basic_se
```

## Optional View Customization

Additionally, it is possible to use `dplyr` to preview the data view of interest
and perform more advanced functions on the data prior to using `loadParquetData`
or the `collect()` function to load it into R. Here we use the `tbl()` function
to access the data view of choice, and pipe it into a `filter()` call to select
only the pathways related to UMP biosynthesis (this is how we can do non-exact
matches). We can then save these calls to a variable prior to loading them into
R, and supply this to `loadParquetData` either instead of or alongside our other
standard filtering arguments.

```{r custom_view}
# Establish connection to example repo
con_ex <- accessParquetData(repo = "waldronlab/metagenomics_mac_examples",
                            data_types = "pathcoverage_unstratified")

# Show view and column info
DBI::dbListTables(con_ex)
parquet_colinfo("pathcoverage_unstratified")

# Create custom view for filtering by non-exact matches
custom_filter <- tbl(con_ex, "pathcoverage_unstratified_pathway") |>
    filter(grepl("UMP biosynthesis", pathway))
custom_filter
```

```{r load_custom}
custom_se <- loadParquetData(con,
                             data_type = "pathcoverage_unstratified",
                             filter_values = list(uuid = c("8793b1dc-3ba1-4591-82b8-4297adcfa1d7",
                                                           "cc1f30a0-45d9-41b1-b592-7d0892919ee7",
                                                           "fb7e8210-002a-4554-b265-873c4003e25f",
                                                           "d9cc81ea-c39e-46a6-a6f9-eb5584b87706",
                                                           "4985aa08-6138-4146-8ae3-952716575395",
                                                           "8eb9f7ae-88c2-44e5-967e-fe7f6090c7af")),
                             custom_view = custom_filter)
custom_se
```

## Large File Considerations

Handling the larger data types, like "genefamilies_stratified" and similar
files, works the exact same way but must take a few factors into consideration.
There are two main limiters:

1. Hugging Face rate limits
2. Result size

To avoid running into Hugging Face's rate limiting (HTTP 429 error), we want to
make sure that all filtering arguments are very selective. Using
"genefamilies_stratified" as an example, we can filter by "uuid" and
"gene_family_uniref", but filtering by "gene_family_species"
*while we are still accessing the parquet in a lazy manner* can throw an error
since a lot of the values in that column show up much more often in the dataset.
To filter these less selective columns, it is recommended to use alternate
filters (e.g., uuid) to create the initial subset and TreeSummarizedExperiment,
then apply the less selective filters to the now locally available data.

This does need to be balanced with your resources for storing and handling the
retrieved data, however. It may be helpful to place a DuckDB database file in a
location capable of large file storage, or run R within a high-resource
environment.

Below, a few example large file queries are executed. They may take a few
seconds to fully load the data.

```{r demo_large_queries}
# Establish connection to genefamilies_stratified files
con_gs <- accessParquetData(data_types = "genefamilies_stratified")

# Example query: we are looking for the below gene families within a particular
# study.
#
# UniRef90_T4BVE4 - present only in SPF mice
# UniRef90_A0A1B1SA57 - present only in WildR mice

# Pull study metadata
selected_samples <- sampleMetadata |>
    filter(study_name == "MazmanianS_DumitrescuDG") |>
    select(where(~ !any(is.na(.x))))

# Do as much as possible to narrow down sample IDs prior to filtering
wildr_ids <- selected_samples |>
    filter(uncurated_donor_microbiome_type == "WildR") |>
    dplyr::pull(uuid)

spf_ids <- selected_samples |>
    filter(uncurated_donor_microbiome_type == "SPF") |>
    dplyr::pull(uuid)

# Run the queries
spf_ex <- loadParquetData(con_gs, "genefamilies_stratified",
                          filter_values = list(gene_family_uniref = "UniRef90_T4BVE4",
                                               uuid = spf_ids))
spf_ex

wildr_ex <- loadParquetData(con_gs, "genefamilies_stratified",
                            filter_values = list(gene_family_uniref = "UniRef90_A0A1B1SA57",
                                                 uuid = wildr_ids))
wildr_ex

# The full sample ID list also works, but is a bit slower
all_ex <- loadParquetData(con_gs, "genefamilies_stratified",
                          filter_values = list(gene_family_uniref = c("UniRef90_T4BVE4", "UniRef90_A0A1B1SA57"),
                                               uuid = selected_samples$uuid))
all_ex
```

